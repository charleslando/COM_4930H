# COM_4930H

#### **Leveraging Jax for Advanced Machine Learning Workflows**

## Table of Contents
1. [Project Proposal](#Project-Proposal)
2. [Learning Jax](#learning-jax)
   1. Why Jax?
   2. Material Used
3. [Reimplementing Existing ML Model With Jax](#reimplementing-existing-ml-model-with-jax)
   1. Previous Model
   2. Training With COCO Dataset
   3. Transformation into Jax
4. [Model Customization and Retraining With Penzai](#model-customization-and-retraining-with-penzai)
5. [Neuron Interpretability](#neuron-interpretability)
6. [Performance Optimization for GPUs and TPUs](#performance-optimizations-for-gpus-and-tpus)
7. [Conclusion](#conclusion)

## Project Proposal
This project involves three main objectives: 
give breif overview of all stuff
1. **Learning Jax**
3. **Reimplementing an Existing Deep Learning Project**  
   2. **Using COCO Dataset**  
         - extracted using tensorflow-datasets  
4. **Neuron Interpretability**  
5. **Model Customization and Retraining**  
6. **Performance optimization for GPUs and TPUs**
7. **Conclusion**
---
### Learning Jax
#### Why Jax?
   - supports optimizations for gpu/tpu high performance
   - good for hardware implementation  
   - easy to write, functional programming style  
   - composition of jax functions are easy, style makes it avoids global state  
   - intermediate language XLA
   - works well with backend implementation
#### Materials Used
TODO

### Reimplementing Existing ML Model With Jax
Utilize Jax to reimplement an existing deep learning project, including datasets and segmentation tasks. This will demonstrate Jax's capabilities in handling complex machine learning workflows.

#### Previous Model
previous model can be found here
#### Training With Coco Dataset
Using TensorFlow Datasets, I extracted the COCO dataset for my training material, which can be found here
#### Transformation Into Jax
TBD

### Model Customization and Retraining With Penzai
Customize models that need to be retrained for new tasks using Penzai. This will involve adapting existing models to new datasets and tasks, showcasing the flexibility and adaptability of machine learning models built with Jax.

### Neuron Interpretability
Identify which neurons contribute to the classification for each class. This involves exploring techniques in neural network interpretability to understand the decision-making process of the model.

### Performance Optimizations for GPUs and TPUs
TBD

### Conclusion
TBD
